## Questions

**Sequence models & Attention mechanism**

1. Sequence to sequence model. Encoding and decoding. 
2. How the translation is picked? Why using a conditional language model instead of a greedy?
3. Explain beam search algorithm. What beam width means? 
4. How error analysis on bam search is conducted? Give an example.
5. What is Bleu Score? Pros and Cons of it?
6. Attention model intuition. The problem of long sentences. General mechanism of work.
![image] 
7. Explain how attention model works in general. How attention is computed?
![img1]
![img2]
8. 